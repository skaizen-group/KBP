{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import json\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "from collections import Counter\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "from spacy.util import minibatch, compounding\n",
    "from spacy.util import decaying\n",
    "import random\n",
    "import re\n",
    "from spacy.gold import GoldParse\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFileList(ftypes, start_path = '.'):\n",
    "    \n",
    "    file_list = []\n",
    "    for dirpath, dirnames, filenames in os.walk(start_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            if fp.endswith(ftypes):\n",
    "                file_list.append(fp)\n",
    "    \n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reads txt, ann files (BRAT) and returns annotated data in spacy format\n",
    "def loadRelations(ann_files, txt_files):\n",
    "    REL = []\n",
    "    for af, tf in zip(ann_files, txt_files):\n",
    "        with open(af, 'r') as ann_data, open(tf, 'r',encoding='utf8') as text_data:\n",
    "            text = text_data.read()\n",
    "            res = []\n",
    "            relist = []\n",
    "            annlist = []\n",
    "            for line in ann_data:\n",
    "                if line.startswith('R'):\n",
    "                    content = line.split()\n",
    "                    if content[1] in ['roleDepartment','hasRole']:\n",
    "                        relist.append(content)\n",
    "                if line.startswith('T'):\n",
    "                    content = line.split()\n",
    "                    annlist.append(content)\n",
    "                        \n",
    "            #print(relist)\n",
    "            #print(annlist)\n",
    "            for r in relist:\n",
    "                #print(r)\n",
    "                s1 = r[2][len('Arg1:'):]\n",
    "                s2 = r[3][len('Arg2:'):]\n",
    "                L = [r[1]]\n",
    "                #print(s1,s2)\n",
    "                for line in annlist:\n",
    "                    if line[0]==s1:\n",
    "                        #print(line)\n",
    "                        #cont = line.split()\n",
    "                        L.append((line[1],int(line[2]),int(line[3]),text[int(line[2]):int(line[3])]))\n",
    "                    if line[0]==s2:\n",
    "                        #cont1 = line.split()\n",
    "                        L.append((line[1],int(line[2]),int(line[3]),text[int(line[2]):int(line[3])]))\n",
    "                #print(L)\n",
    "                if r[1] == 'hasRole':\n",
    "                    if L[1][0]=='Person':\n",
    "                        res += [(L[0],L[1][1:],L[2][1:])]\n",
    "                    else:\n",
    "                        res+= [(L[0],L[2][1:],L[1][1:])]\n",
    "                if r[1] == 'roleDepartment':\n",
    "                    if L[1][0]=='Role':\n",
    "                        res+= [(L[0],L[1][1:],L[2][1:])]\n",
    "                    else:\n",
    "                        res+= [(L[0],L[2][1:],L[1][1:])]\n",
    "            if res: REL.append((text,{\"relations\": res}))    \n",
    "            \n",
    "            \n",
    "    return REL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds = loadRelations(ann, txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tokenize\n",
    "def splitRelations(old_train):\n",
    "    new_train = []\n",
    "    for article in old_train:\n",
    "        old_ents = article[1]['relations']\n",
    "        full_text = article[0]\n",
    "        doc_sents = tokenize.sent_tokenize(article[0], language='french')\n",
    "        \n",
    "        for ind, sent in enumerate(doc_sents):\n",
    "            new_ents = []\n",
    "            sent_start = full_text.index(sent)\n",
    "            sent_end = sent_start + len(sent)\n",
    "            \n",
    "            for item in old_ents:\n",
    "                #print(item[1][1])\n",
    "                if (sent_start <= item[1][1] <= sent_end) and (sent_start <= item[2][1] <= sent_end):\n",
    "                    new_ents.append((item[0], (item[1][0]-sent_start, item[1][1]-sent_start, item[1][2]),(item[2][0]-sent_start, item[2][1]-sent_start, item[2][2])))\n",
    "            if new_ents:\n",
    "                new_train.append((sent, {'relations': new_ents}))\n",
    "    return new_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_spans(spans):\n",
    "    # Filter a sequence of spans so they don't contain overlaps\n",
    "    get_sort_key = lambda span: (span.end - span.start, span.start)\n",
    "    sorted_spans = sorted(spans, key=get_sort_key, reverse=True)\n",
    "    result = []\n",
    "    seen_tokens = set()\n",
    "    for span in sorted_spans:\n",
    "        if span.start not in seen_tokens and span.end - 1 not in seen_tokens:\n",
    "            result.append(span)\n",
    "            seen_tokens.update(range(span.start, span.end))\n",
    "    return result\n",
    "\n",
    "def extract_relations(doc):\n",
    "    \n",
    "    spans = list(doc.ents)\n",
    "    spans = filter_spans(spans)\n",
    "    with doc.retokenize() as retokenizer:\n",
    "        for span in spans:\n",
    "            retokenizer.merge(span)\n",
    "\n",
    "    relations = []\n",
    "    for target in filter(lambda w: w.ent_type_ == 'ROL', doc):\n",
    "        if target.dep_ == \"obl\":\n",
    "            subject = [w for w in target.head.lefts if w.dep_ == \"nsubj:pass\"]\n",
    "            if subject:\n",
    "                if subject[0].ent_type_ == 'PER':\n",
    "                    relations.append(('hasRole',str(subject[0]), str(target)))\n",
    "                if subject[0].ent_type_ == 'ORG':\n",
    "                    relations.append(('roleDepartment', str(target), str(subject[0])))\n",
    "            #'Ce matin, Valérie Pécresse sera installée à la présidence de la région Ile-de-France.',\n",
    "            #('hasRole','Valérie Pécresse','présidence')\n",
    "\n",
    "        if target.dep_ == \"appos\":\n",
    "            if target.head.ent_type_ == 'PER':\n",
    "                relations.extend([('hasRole',str(target.head), str(target))])\n",
    "            if target.head.ent_type_ == 'ORG':\n",
    "                relations.extend([('roleDepartment', str(target), str(target.head))])\n",
    "            #« Ce sont des entreprises très souples, dans lesquelles la direction peut prendre très vite des décisions », \n",
    "            #commente Jacky Lintignat, directeur général de KPMG France.',\n",
    "            #('hasRole', 'Jacky Lintignat', 'directeur général')\n",
    "            else :\n",
    "                mod = [target.head]\n",
    "                if mod:\n",
    "                    mod = [w for w in mod[0].children if w.dep_ == \"nmod\"]\n",
    "                    if mod:\n",
    "                        mod = mod[0]\n",
    "                        if mod.ent_type_ == 'PER':\n",
    "                            relations.extend([('hasRole',str(mod), str(target))])\n",
    "                        if mod.ent_type_ == 'ORG':\n",
    "                            relations.extend([('roleDepartment',str(target), str(mod))])\n",
    "                        #'« Ce discours était un signal politique important, analyse Shahin Vallée, chercheur invité au cercle \n",
    "                        #de réflexion européen Bruegel.',\n",
    "                        #('hasRole', 'Shahin Vallée', 'chercheur')\n",
    "            mod1 = [w for w in target.children if w.dep_ =='nmod' and w.ent_type_ in [\"PER\",\"ORG\"]]\n",
    "            if mod1:\n",
    "                mod1 = mod1[0]\n",
    "                if mod1.ent_type_ == 'PER':\n",
    "                    relations.extend([('hasRole',str(mod1), str(target))])\n",
    "                if mod1.ent_type_ == 'ORG':\n",
    "                    relations.extend([('roleDepartment', str(target), str(mod1))])\n",
    "                #\"Après Hubert Joly, le patron de l'américain Best Buy, c'est Alain Caparros, celui de l'allemand Rewe, qui a \n",
    "                #officiellement décliné.\",\n",
    "                #('roleDepartment', 'patron', 'Best Buy')\n",
    "            \n",
    "        if target.dep_ == \"acl\":\n",
    "            mod1 = [w for w in target.children if w.dep_ =='nmod' and w.ent_type_ in [\"PER\",\"ORG\"]]\n",
    "            if mod1:\n",
    "                mod1 = mod1[0]\n",
    "                if mod1.ent_type_ == 'PER':\n",
    "                    relations.extend([('hasRole',str(mod1), str(target))])\n",
    "                if mod1.ent_type_ == 'ORG':\n",
    "                    relations.extend([('roleDepartment', str(target), str(mod1))])\n",
    "                #\"« Si la concurrence s'intensifie, ils ne pourront pas y échapper », prédit Philippe Lerouge, fondateur \n",
    "                #du Salon Mobile Payment.\",\n",
    "                #('roleDepartment', 'fondateur', 'Salon Mobile Payment')\n",
    "        if target.dep_ == \"nsubj\":\n",
    "            mod = [w for w in target.children if w.dep_ in [\"obj\",\"appos\"]]\n",
    "            if mod:\n",
    "                mod = mod[0]\n",
    "                if mod.ent_type_ == 'PER':\n",
    "                    relations.extend([('hasRole',str(mod), str(target))])\n",
    "                if mod.ent_type_ == 'ORG':\n",
    "                    relations.extend([('roleDepartment', str(target), str(mod))])\n",
    "                #'Le PDG de la division aviation commerciale d\\'Airbus, Fabrice Brégier, a estimé que cette livraison marquait \"\n",
    "                #la renaissance de l\\'aviation d\\'Iran Air\" et constituait \"un des développements les plus importants de \n",
    "                #l\\'industrie (aéronautique) depuis bien des années\".',\n",
    "                #('hasRole', 'Fabrice Brégier', 'PDG')\n",
    "        \n",
    "        subject = [w for w in target.children if w.dep_ in (\"nmod\", \"nsubj\",\"obl\")]\n",
    "        if subject:\n",
    "            if subject[0].ent_type_ == 'PER':\n",
    "                relations.extend([('hasRole',str(s), str(target)) for s in subject])\n",
    "            if subject[0].ent_type_ == 'ORG':\n",
    "                relations.extend([('roleDepartment', str(target), str(s)) for s in subject])\n",
    "            #'« Les mauvais taux de transformation ne nous incitent pas à investir pour adapter nos jeux aux terminaux sous \n",
    "            #Android », explique Gonzague de Vallois, vice-président de Gameloft.',\n",
    "            #('roleDepartment', 'vice-président', 'Gameloft')]})\n",
    "\n",
    "    return relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"./nerav1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate function takes the dataset & ner model\n",
    "def evaluate(test_data, model):\n",
    "    \n",
    "    ds = splitRelations(test_data)\n",
    "    s, m, n = 0, 0, 0\n",
    "    for item in ds:\n",
    "        test_text = item[0]\n",
    "        golds = [(gold[0],gold[1][2],gold[2][2]) for gold in item[1]['relations'] if gold[0] in ['roleDepartment','hasRole']]\n",
    "        #doc = model(test_text)\n",
    "        pred = extract_relations(model(test_text))\n",
    "        n += len(golds)\n",
    "        m += len(pred)\n",
    "        s += len([element for element in pred if element in golds])\n",
    "        \n",
    "    try:\n",
    "        precision = s/m\n",
    "    except ZeroDivisionError:\n",
    "        precision = float('nan')\n",
    "\n",
    "    try:\n",
    "        recall = s/n    \n",
    "    except ZeroDivisionError:\n",
    "        recall = float('nan')\n",
    "        \n",
    "    try:\n",
    "        f1 = 2*(recall*precision)/(recall+precision)\n",
    "    except ZeroDivisionError:\n",
    "        f1 = float('nan')\n",
    "    \n",
    "    #print(\"Precision : \", precision)\n",
    "    #print('Recall : ', recall)\n",
    "    #print('F1 score : ', f1)\n",
    "    \n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlaps(element, golds):    \n",
    "    ranges = [g for g in golds if g[0]==element[0]]\n",
    "    \n",
    "    return any ((element[1] in g[1] or g[1] in element[1]) and (element[2] in g[2] or g[2] in element[2]) for g in ranges)\n",
    "\n",
    "def evaluate_partials(test_data, model):\n",
    "    \n",
    "    ds = splitRelations(test_data)\n",
    "    s, m, n = 0, 0, 0\n",
    "    for item in test_data:\n",
    "        test_text = item[0]\n",
    "        golds = [(gold[0],gold[1][2],gold[2][2]) for gold in item[1]['relations'] if gold[0] in ['roleDepartment','hasRole']]\n",
    "        \n",
    "        pred = extract_relations(model(test_text))\n",
    "        n += len(golds)\n",
    "        m += len(pred)\n",
    "        s += len([element for element in pred if overlaps(element, golds)])\n",
    "        \n",
    "    try:\n",
    "        precision = s/m\n",
    "    except ZeroDivisionError:\n",
    "        precision = float('nan')\n",
    "\n",
    "    try:\n",
    "        recall = s/n    \n",
    "    except ZeroDivisionError:\n",
    "        recall = float('nan')\n",
    "        \n",
    "    try:\n",
    "        f1 = 2*(recall*precision)/(recall+precision)\n",
    "    except ZeroDivisionError:\n",
    "        f1 = float('nan')\n",
    "    \n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
