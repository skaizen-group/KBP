{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INITIALISATION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importation des librairies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from neo4j import GraphDatabase\n",
    "import glob, os\n",
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initatilisation des variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbRelationAnn = 0\n",
    "nbEntiteAnn = 0\n",
    "\n",
    "nbRelationPred = 0\n",
    "nbEntitePred = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = {\n",
    "    'Person': 'PER',\n",
    "    'Location': 'LOC',\n",
    "    'City': 'LOC',\n",
    "    'LocalRegion': 'LOC',\n",
    "    'Country': 'LOC',\n",
    "    'WorldRegion': 'LOC',\n",
    "    'Organization': 'ORG',\n",
    "    'Association': 'ORG',\n",
    "    'GeopoliticalEntity': 'ORG',\n",
    "    'Company': 'ORG',\n",
    "    'Media': 'ORG',\n",
    "    'Role': 'ROL',\n",
    "    'Currency': 'CUR'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fonction donnant le contexte des relations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getContext(tabText,nbCaractere):\n",
    "    lenTxt1 = 0\n",
    "    lenTxt2 = len(tabText[0])\n",
    "    for i in range(0,len(tabText)):\n",
    "        if nbCaractere > lenTxt1 and nbCaractere <= lenTxt2 :\n",
    "            return (i)\n",
    "        else :\n",
    "            lenTxt1 = lenTxt1 + len(tabText[i])\n",
    "            if( i +1 < len(tabText) ) :\n",
    "                lenTxt2 = lenTxt2 + len(tabText[i+1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTATION DANS NEO4J DES ENTITES ET DES RELATIONS A PARTIR DES ANNOTATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exemple d'utilisation avec le sample M**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample_M/M_ACCOR.ann\n",
      "Sample_M/M_ACQUISITION.ann\n",
      "Sample_M/M_ACTIVITE.ann\n",
      "Sample_M/M_ADMINISTRATION.ann\n",
      "Sample_M/M_CONTINENT.ann\n",
      "Sample_M/M_DOLLAR.ann\n",
      "Sample_M/M_FRANCE.ann\n",
      "Sample_M/M_FUSION.ann\n",
      "Sample_M/M_IMMOBILIER.ann\n",
      "Sample_M/M_INFORMATIQUE.ann\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#Initialisation de la connection a Neo4j\n",
    "driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"i-0578b6cebb222aa18\"))\n",
    "\n",
    "#Chemin du dossier contenant les fichiers\n",
    "path = \"Sample_M\"\n",
    "files = [f for f in glob.glob(path +\"**/*.ann\" )]\n",
    "for file_path in files:\n",
    "    file = open(file_path, \"r\",encoding='utf-8-sig')\n",
    "    line = file.readline()\n",
    "    print(file_path)\n",
    "    fileTxt = open(file_path.replace(\"ann\",\"txt\"), \"r\")\n",
    "    text= fileTxt.read()\n",
    "    tokText=tokenize.sent_tokenize(text, language='french')\n",
    "    \n",
    "\n",
    "    #Dictionnaire des entité et relation du fichier\n",
    "    tabLine = {}\n",
    "\n",
    "    #Les entités où l'on souhaite avoir des doublons\n",
    "    listeDoublon = [\"Role\",\"Activity\",'ROL']\n",
    "\n",
    "    #Lecture du fichier ligne par ligne\n",
    "    while line:\n",
    "        #driver = GraphDatabase.driver(\"bolt://15.188.27.124:7687\", auth=(\"neo4j\", \"i-0578b6cebb222aa18\"))\n",
    "        driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"i-0578b6cebb222aa18\"))\n",
    "        strLine = line.strip()\n",
    "        \n",
    "        #traitement de la ligne en séparant les différents champs\n",
    "        strLine = strLine.replace(\"\\t\",\" \")\n",
    "        strLine = strLine.replace(\"\\uffef\",\"\")\n",
    "        indice = strLine.split(\" \",4)[0]\n",
    "\n",
    "        #Traitement dans le cas d'une entité\n",
    "        if strLine[0] == 'T' :\n",
    "\n",
    "            nbEntiteAnn += 1\n",
    "            \n",
    "            tabLine[indice] = strLine.split(\" \",4)\n",
    "            \n",
    "            tabLine[indice][0] = tabLine[indice][0].replace('\"',\"'\" )\n",
    "            tabLine[indice][4] = tabLine[indice][4].replace('\"',\"'\" )\n",
    "            \n",
    "            nomT = tabLine[indice][1]\n",
    "            if keys.get(nomT) != None:\n",
    "                nomT = keys.get(nomT)\n",
    "\n",
    "            #Requete pour ajouter l'entité à Neo4j\n",
    "            if nomT in listeDoublon :\n",
    "                query = \"CREATE (:\" + nomT + \"{nom:\\\"\" + tabLine[indice][4] + \"\\\" , id :\\\"\" + tabLine[indice][0] + \"\\\"}) \"  \n",
    "            else :\n",
    "                query = \"MERGE (:\" + nomT + \"{nom:\\\"\" + tabLine[indice][4] + \"\\\"}) \"\n",
    "\n",
    "        #traitement dans le cas d'une relation\n",
    "        elif strLine[0] == 'R' :\n",
    "\n",
    "            try :\n",
    "                \n",
    "                nbRelationAnn += 1\n",
    "                \n",
    "                tabLine[indice] = strLine.split(\" \",4)\n",
    "                tabLine[indice][2] = tabLine[indice][2].split(\":\")[1]\n",
    "                tabLine[indice][3] = tabLine[indice][3].split(\":\")[1]\n",
    "                nomR = tabLine[indice][1]\n",
    "                R1 = tabLine[indice][2]\n",
    "                R2 = tabLine[indice][3]\n",
    "\n",
    "                tabLine[R1][1] = tabLine[R1][1].replace('\"',\"'\" )\n",
    "                tabLine[R1][4] = tabLine[R1][4].replace('\"',\"'\" )\n",
    "\n",
    "                tabLine[R2][1] = tabLine[R2][1].replace('\"',\"'\" )\n",
    "                tabLine[R2][4] = tabLine[R2][4].replace('\"',\"'\" )\n",
    "\n",
    "\n",
    "                if keys.get(tabLine[R1][1]) != None:\n",
    "                    tabLine[R1][1] = keys.get(tabLine[R1][1])\n",
    "                    \n",
    "                if keys.get(tabLine[R2][1]) != None:\n",
    "                    tabLine[R2][1] = keys.get(tabLine[R2][1])\n",
    "                    \n",
    "                nomR1 = tabLine[R1][1]\n",
    "                nomR2 = tabLine[R2][1]\n",
    "\n",
    "                debutRole = int(tabLine[R1][2])\n",
    "                finRole = int(tabLine[R2][3])\n",
    "\n",
    "                nb1=getContext(tokText,debutRole)\n",
    "                nb2=getContext(tokText,finRole)\n",
    "                if (nb1 != nb2 ):\n",
    "                    context = tokText[nb1]+\" | \"+tokText[nb2]\n",
    "                else : \n",
    "                    context = tokText[nb1]\n",
    "                \n",
    "                context= context.replace('\"',\"'\")\n",
    "                #Les différents cas de figure si l'on a affaire à des chaines de relations avec des doublons\n",
    "                if nomR1 in listeDoublon and nomR2 not in listeDoublon :\n",
    "                    query =  \"MATCH ( T1:\" + tabLine[R1][1] + \"{nom:\\\"\" + tabLine[R1][4] + \"\\\" , id :\\\"\" + R1 + \"\\\"} ) \"\n",
    "                    query += \"MATCH ( T2:\" + tabLine[R2][1] + \"{nom:\\\"\" + tabLine[R2][4] + \"\\\"} ) \"\n",
    "            \n",
    "                    query += \"OPTIONAL MATCH (( T1 )-[r1:\" + nomR + \"]->( T2 )) \"\n",
    "                    query +=\"FOREACH (usertype IN CASE WHEN exists (( T1 )-[:\" + nomR + \"]->( T2 )) = False  THEN [1] ELSE [] END | MERGE ( T1 )-[:\" + nomR + \" {context : [\\\"\"+context+\"\\\"],type:'A',file:\\\"\"+file_path+\"\\\"} ]->( T2 ) ) \"\n",
    "                    query +=\"FOREACH (usertype IN CASE WHEN exists (( T1 )-[:\" + nomR + \"]->( T2 )) = True  THEN [1] ELSE [] END | SET r1.context = r1.context + \\\"\"+ context +\"\\\") \"\n",
    "\n",
    "                elif nomR1 not in listeDoublon and nomR2 in listeDoublon:\n",
    "                    query =  \"MATCH ( T1:\" + tabLine[R1][1] + \"{nom:\\\"\" + tabLine[R1][4] + \"\\\"} ) \"\n",
    "                    query += \"MATCH ( T2:\" + tabLine[R2][1] + \"{nom:\\\"\" + tabLine[R2][4] + \"\\\" , id :\\\"\" + R2 + \"\\\"} ) \"\n",
    "                    query += \"OPTIONAL MATCH (( T1 )-[r1:\" + nomR + \"]->( T2 )) \"\n",
    "                    query +=\"FOREACH (usertype IN CASE WHEN exists (( T1 )-[:\" + nomR + \"]->( T2 )) = False  THEN [1] ELSE [] END | MERGE ( T1 )-[:\" + nomR + \" {context : [\\\"\"+context+\"\\\"],type:'A',file:\\\"\"+file_path+\"\\\"} ]->( T2 ) ) \"\n",
    "                    query +=\"FOREACH (usertype IN CASE WHEN exists (( T1 )-[:\" + nomR + \"]->( T2 )) = True  THEN [1] ELSE [] END | SET r1.context = r1.context + \\\"\"+ context +\"\\\") \"\n",
    "\n",
    "                elif nomR1 in listeDoublon and nomR2 in listeDoublon :\n",
    "                    query =  \"MATCH ( T1:\" + tabLine[R1][1] + \"{nom:\\\"\" + tabLine[R1][4] + \"\\\" , id :\\\"\" + R1 + \"\\\"} ) \"\n",
    "                    query += \"MATCH ( T2:\" + tabLine[R2][1] + \"{nom:\\\"\" + tabLine[R2][4] + \"\\\" , id :\\\"\" + R2 + \"\\\"} ) \"\n",
    "\n",
    "                    query += \"OPTIONAL MATCH (( T1 )-[r1:\" + nomR + \"]->( T2 )) \"\n",
    "                    query +=\"FOREACH (usertype IN CASE WHEN exists (( T1 )-[:\" + nomR + \"]->( T2 )) = False  THEN [1] ELSE [] END | MERGE ( T1 )-[:\" + nomR + \" {context : [\\\"\"+context+\"\\\"],type:'A',file:\\\"\"+file_path+\"\\\"} ]->( T2 ) ) \"\n",
    "                    query +=\"FOREACH (usertype IN CASE WHEN exists (( T1 )-[:\" + nomR + \"]->( T2 )) = True  THEN [1] ELSE [] END | SET r1.context = r1.context + \\\"\"+ context +\"\\\") \"\n",
    "\n",
    "                else :\n",
    "                    query =  \"MATCH ( T1:\" + tabLine[R1][1] + \"{nom:\\\"\" + tabLine[R1][4] + \"\\\"} ) \"\n",
    "                    query += \"MATCH ( T2:\" + tabLine[R2][1] + \"{nom:\\\"\" + tabLine[R2][4] + \"\\\"} ) \"\n",
    "            \n",
    "\n",
    "                    query += \"OPTIONAL MATCH (( T1 )-[r1:\" + nomR + \"]->( T2 )) \"\n",
    "                    query +=\"FOREACH (usertype IN CASE WHEN exists (( T1 )-[:\" + nomR + \"]->( T2 )) = False  THEN [1] ELSE [] END | MERGE ( T1 )-[:\" + nomR + \" {context : [\\\"\"+context+\"\\\"],type:'A',file:\\\"\"+file_path+\"\\\"} ]->( T2 ) ) \"\n",
    "                    query +=\"FOREACH (usertype IN CASE WHEN exists (( T1 )-[:\" + nomR + \"]->( T2 )) = True  THEN [1] ELSE [] END | SET r1.context = r1.context + \\\"\"+ context +\"\\\") \"\n",
    "                \n",
    "            except KeyError as e:\n",
    "                print(\"--------------------------------\")\n",
    "                print(file)\n",
    "                print(e)\n",
    "                print(strLine)\n",
    "            except TypeError as e2:\n",
    "                pass\n",
    "\n",
    "        #On lit la ligne suivante\n",
    "        line = file.readline()\n",
    "        #On execute la requete\n",
    "        driver.session().run(query) \n",
    "    #traitement finale où l'on supprime tous les doublons\n",
    "    query= \"\"\"\n",
    "    MATCH (a)-[r1]->(b) , (c)-[r2]->(d)\n",
    "    WHERE \n",
    "    b<>d and\n",
    "    a.nom = c.nom and b.nom = d.nom\n",
    "    call apoc.refactor.mergeNodes([b,d],{properties:\"combine\", mergeRels:true}) yield node\n",
    "    return \"none\"\n",
    "    \"\"\"\n",
    "    driver.session().run(query) \n",
    "    #requete permettant de supprimer la propriété id qui été utilisé pour les relations\n",
    "    query= \"\"\"\n",
    "    MATCH (n)\n",
    "    remove n.id\n",
    "    return n\n",
    "    \"\"\"\n",
    "    driver.session().run(query) \n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chargement du model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"NER_Model_11Dec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importation dans Neo4j des entités prédites**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample_M/M_ACCOR.txt\n",
      "Sample_M/M_ACQUISITION.txt\n",
      "Sample_M/M_ACTIVITE.txt\n",
      "Sample_M/M_ADMINISTRATION.txt\n",
      "Sample_M/M_CONTINENT.txt\n",
      "Sample_M/M_DOLLAR.txt\n",
      "Sample_M/M_FRANCE.txt\n",
      "Sample_M/M_FUSION.txt\n",
      "Sample_M/M_IMMOBILIER.txt\n",
      "Sample_M/M_INFORMATIQUE.txt\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#Initialisation de la connection a Neo4j\n",
    "#driver = GraphDatabase.driver(\"bolt://15.188.27.124:7687\", auth=(\"neo4j\", \"i-0578b6cebb222aa18\"))\n",
    "driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"i-0578b6cebb222aa18\"))\n",
    "#Chemin du dossier contenant les fichiers\n",
    "path = \"Sample_M\"\n",
    "files = [f for f in glob.glob(path +\"**/*.txt\" )]\n",
    "listeDoublon = [\"ROL\",\"Role\",\"Activity\"]\n",
    "\n",
    "for file_path in files:\n",
    "    file = open(file_path, \"r\",encoding='utf-8-sig')\n",
    "    print(file_path)\n",
    "    \n",
    "    text= file.read()\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    for token in doc.ents:\n",
    "        #if token.label_  in listeDoublon :\n",
    "        nbEntitePred += 1\n",
    "        if token.label_  in listeDoublon :\n",
    "            \n",
    "            #query = \"MERGE (:\" + token.label_ + \"{nom:\\\"\" + '{}'.format(token.start_char) + \"\\\" , end\\\"\" + '{}'.format(token.end_char) + \"\\\" }) \"\n",
    "            query =  \"CREATE (:\" + token.label_ + \"{nom:\\\"\" + token.text + \"\\\" , id:\\\"\" + '{}'.format(token.start_char) + \"\\\" }) \"\n",
    "            #idEnt+=1\n",
    "        else :\n",
    "            query = \"MERGE (:\" + token.label_ + \"{nom:\\\"\" + token.text + \"\\\"}) \"\n",
    "        \n",
    "            #print(token.text, token.start_char, token.end_char, token.label_)\n",
    "            #print(query)\n",
    "        driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"i-0578b6cebb222aa18\"))\n",
    "        driver.session().run(query)  \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fonction pour extraire les relations hasRole**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relate(TEXTS):\n",
    "    relationsTab =[]\n",
    "    for text in TEXTS:\n",
    "        print('\\n>> '+text+'\\n')\n",
    "        doc = nlp(text)\n",
    "        relations = extract_relations(doc)\n",
    "        relations.append(text)\n",
    "        relationsTab.append(relations)\n",
    "\n",
    "    return relationsTab\n",
    "\n",
    "def filter_spans(spans):\n",
    "    # Filter a sequence of spans so they don't contain overlaps\n",
    "    get_sort_key = lambda span: (span.end - span.start, span.start)\n",
    "    sorted_spans = sorted(spans, key=get_sort_key, reverse=True)\n",
    "    result = []\n",
    "    seen_tokens = set()\n",
    "    for span in sorted_spans:\n",
    "        if span.start not in seen_tokens and span.end - 1 not in seen_tokens:\n",
    "            result.append(span)\n",
    "            seen_tokens.update(range(span.start, span.end))\n",
    "    return result\n",
    "\n",
    "\n",
    "def extract_relations(doc):\n",
    "    \n",
    "    spans = list(doc.ents)\n",
    "    spans = filter_spans(spans)\n",
    "    with doc.retokenize() as retokenizer:\n",
    "        for span in spans:\n",
    "            retokenizer.merge(span)\n",
    "\n",
    "    relations = []\n",
    "    for target in filter(lambda w: w.ent_type_ == 'ROL', doc):\n",
    "        if target.dep_ == \"obl\":\n",
    "            subject = [w for w in target.head.lefts if w.dep_ == \"nsubj:pass\"]\n",
    "            if subject:\n",
    "                if subject[0].ent_type_ == 'PER':\n",
    "                    relations.append(('hasRole','PER',str(subject[0]),'ROL',str(target),target.idx))\n",
    "                if subject[0].ent_type_ == 'ORG':\n",
    "\n",
    "                    relations.append(('roleDepartment','ROL', str(target),'ORG', str(subject[0]),target.idx))\n",
    "            #'Ce matin, Valérie Pécresse sera installée à la présidence de la région Ile-de-France.',\n",
    "            #('hasRole','Valérie Pécresse','présidence')\n",
    "\n",
    "        if target.dep_ == \"appos\":\n",
    "            if target.head.ent_type_ == 'PER':\n",
    "                relations.extend([('hasRole','PER',str(target.head),'ROL', str(target),target.idx)])\n",
    "            if target.head.ent_type_ == 'ORG':\n",
    "\n",
    "                relations.extend([('roleDepartment','ROL', str(target),'ORG' ,str(target.head),target.idx)])\n",
    "            #« Ce sont des entreprises très souples, dans lesquelles la direction peut prendre très vite des décisions », \n",
    "            #commente Jacky Lintignat, directeur général de KPMG France.',\n",
    "            #('hasRole', 'Jacky Lintignat', 'directeur général')\n",
    "            else :\n",
    "                mod = [target.head]\n",
    "                if mod:\n",
    "                    mod = [w for w in mod[0].children if w.dep_ == \"nmod\"]\n",
    "                    if mod:\n",
    "                        mod = mod[0]\n",
    "                        if mod.ent_type_ == 'PER':\n",
    "\n",
    "                            relations.extend([('hasRole','PER',str(mod),'ROL', str(target),target.idx)])\n",
    "                        if mod.ent_type_ == 'ORG':\n",
    "                            relations.extend([('roleDepartment','ROL',str(target),'ORG', str(mod),target.idx)])\n",
    "                        #'« Ce discours était un signal politique important, analyse Shahin Vallée, chercheur invité au cercle \n",
    "                        #de réflexion européen Bruegel.',\n",
    "                        #('hasRole', 'Shahin Vallée', 'chercheur')\n",
    "            mod1 = [w for w in target.children if w.dep_ =='nmod' and w.ent_type_ in [\"PER\",\"ORG\"]]\n",
    "            if mod1:\n",
    "                mod1 = mod1[0]\n",
    "                if mod1.ent_type_ == 'PER':\n",
    "                    relations.extend([('hasRole','PER',str(mod1),'ROL', str(target),target.idx)])\n",
    "                if mod1.ent_type_ == 'ORG':\n",
    "                    relations.extend([('roleDepartment','ROL', str(target),'ORG', str(mod1),target.idx)])\n",
    "                #\"Après Hubert Joly, le patron de l'américain Best Buy, c'est Alain Caparros, celui de l'allemand Rewe, qui a \n",
    "                #officiellement décliné.\",\n",
    "                #('roleDepartment', 'patron', 'Best Buy')\n",
    "            \n",
    "        if target.dep_ == \"acl\":\n",
    "            mod1 = [w for w in target.children if w.dep_ =='nmod' and w.ent_type_ in [\"PER\",\"ORG\"]]\n",
    "            if mod1:\n",
    "                mod1 = mod1[0]\n",
    "                if mod1.ent_type_ == 'PER':\n",
    "                    relations.extend([('hasRole','PER',str(mod1),'ROL',  str(target),target.idx)])\n",
    "                if mod1.ent_type_ == 'ORG':\n",
    "                    relations.extend([('roleDepartment','ROL', str(target),'ORG',  str(mod1),target.idx)])\n",
    "                #\"« Si la concurrence s'intensifie, ils ne pourront pas y échapper », prédit Philippe Lerouge, fondateur \n",
    "                #du Salon Mobile Payment.\",\n",
    "                #('roleDepartment', 'fondateur', 'Salon Mobile Payment')\n",
    "        if target.dep_ == \"nsubj\":\n",
    "            mod = [w for w in target.children if w.dep_ in [\"obj\",\"appos\"]]\n",
    "            if mod:\n",
    "                mod = mod[0]\n",
    "                if mod.ent_type_ == 'PER':\n",
    "                    relations.extend([('hasRole','PER',str(mod),'ROL',  str(target),target.idx)])\n",
    "                if mod.ent_type_ == 'ORG':\n",
    "                    relations.extend([('roleDepartment','ROL', str(target),'ORG',  str(mod),target.idx)])\n",
    "                #'Le PDG de la division aviation commerciale d\\'Airbus, Fabrice Brégier, a estimé que cette livraison marquait \"\n",
    "                #la renaissance de l\\'aviation d\\'Iran Air\" et constituait \"un des développements les plus importants de \n",
    "                #l\\'industrie (aéronautique) depuis bien des années\".',\n",
    "                #('hasRole', 'Fabrice Brégier', 'PDG')\n",
    "        \n",
    "        subject = [w for w in target.children if w.dep_ in (\"nmod\", \"nsubj\",\"obl\")]\n",
    "        if subject:\n",
    "            if subject[0].ent_type_ == 'PER':\n",
    "                relations.extend([('hasRole','PER',str(s),'ROL',  str(target),target.idx) for s in subject])\n",
    "            if subject[0].ent_type_ == 'ORG':\n",
    "                relations.extend([('roleDepartment','ROL', str(target),'ORG',  str(s),target.idx) for s in subject])\n",
    "            #'« Les mauvais taux de transformation ne nous incitent pas à investir pour adapter nos jeux aux terminaux sous \n",
    "            #Android », explique Gonzague de Vallois, vice-président de Gameloft.',\n",
    "            #('roleDepartment', 'vice-président', 'Gameloft')]})\n",
    "\n",
    "    return relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_spans(spans):\n",
    "    # Filter a sequence of spans so they don't contain overlaps\n",
    "    get_sort_key = lambda span: (span.end - span.start, span.start)\n",
    "    sorted_spans = sorted(spans, key=get_sort_key, reverse=True)\n",
    "    result = []\n",
    "    seen_tokens = set()\n",
    "    for span in sorted_spans:\n",
    "        if span.start not in seen_tokens and span.end - 1 not in seen_tokens:\n",
    "            result.append(span)\n",
    "            seen_tokens.update(range(span.start, span.end))\n",
    "    return result\n",
    "\n",
    "def extract_relationsCurrency(doc):\n",
    "    \n",
    "    spans = list(doc.ents)\n",
    "    spans = filter_spans(spans)\n",
    "    with doc.retokenize() as retokenizer:\n",
    "        for span in spans:\n",
    "            retokenizer.merge(span)\n",
    "            \n",
    "    relations = []\n",
    "    nbCurrency = 0\n",
    "    nbCurrencyPred = 0\n",
    "    for target in filter(lambda w: w.ent_type_ == 'CUR', doc) :\n",
    "        bol = nbCurrencyPred\n",
    "        for i in range(-2,2):\n",
    "            if ( doc[target.i+i].ent_type_ == 'MISC' or doc[target.i+i].dep_ == 'nummod'):\n",
    "                relations.extend([('hasCurrency','MISC',str(doc[target.i+i].text),'CUR',  str(target),target.idx)])\n",
    "\n",
    "    return relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample_M/M_ACCOR.txt\n",
      "Sample_M/M_ACQUISITION.txt\n",
      "Sample_M/M_ACTIVITE.txt\n",
      "Sample_M/M_ADMINISTRATION.txt\n",
      "Sample_M/M_CONTINENT.txt\n",
      "Sample_M/M_DOLLAR.txt\n",
      "Sample_M/M_FRANCE.txt\n",
      "Sample_M/M_FUSION.txt\n",
      "Sample_M/M_IMMOBILIER.txt\n",
      "Sample_M/M_INFORMATIQUE.txt\n"
     ]
    }
   ],
   "source": [
    "#Initialisation de la connection a Neo4j\n",
    "\n",
    "#Chemin du dossier contenant les fichiers\n",
    "path = \"Sample_M\"\n",
    "files = [f for f in glob.glob(path +\"**/*.txt\" )]\n",
    "listeDoublon = [\"ROL\",\"Role\",\"Activity\"]\n",
    "nbRel = 0\n",
    "#relations=[]\n",
    "for file_path in files:\n",
    "    file = open(file_path, \"r\",encoding='utf-8-sig')\n",
    "    print(file_path)\n",
    "    \n",
    "    text= file.read()\n",
    "    tokText=tokenize.sent_tokenize(text, language='french')\n",
    "    relations=[]\n",
    "    doc = nlp(text)\n",
    "    #relations.extend(extract_relations(doc))\n",
    "    relations.extend(extract_relationsCurrency(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample_M/M_ACCOR.txt\n",
      "Sample_M/M_ACQUISITION.txt\n",
      "Sample_M/M_ACTIVITE.txt\n",
      "Sample_M/M_ADMINISTRATION.txt\n",
      "Sample_M/M_CONTINENT.txt\n",
      "Sample_M/M_DOLLAR.txt\n",
      "Sample_M/M_FRANCE.txt\n",
      "Sample_M/M_FUSION.txt\n",
      "Sample_M/M_IMMOBILIER.txt\n",
      "Sample_M/M_INFORMATIQUE.txt\n",
      "nb relations : 67\n"
     ]
    }
   ],
   "source": [
    "#Initialisation de la connection a Neo4j\n",
    "#driver = GraphDatabase.driver(\"bolt://15.188.27.124:7687\", auth=(\"neo4j\", \"i-0578b6cebb222aa18\"))\n",
    "driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"i-0578b6cebb222aa18\"))\n",
    "#Chemin du dossier contenant les fichiers\n",
    "path = \"Sample_M\"\n",
    "files = [f for f in glob.glob(path +\"**/*.txt\" )]\n",
    "listeDoublon = [\"ROL\",\"Role\",\"Activity\",\"CUR\",\"MISC\"]\n",
    "nbRel = 0\n",
    "\n",
    "for file_path in files:\n",
    "    file = open(file_path, \"r\",encoding='utf-8-sig')\n",
    "    print(file_path)\n",
    "    \n",
    "    text= file.read()\n",
    "    tokText=tokenize.sent_tokenize(text, language='french')\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    relations=[]\n",
    "    relations.extend(extract_relations(doc))\n",
    "    relations.extend(extract_relationsCurrency(doc))\n",
    "\n",
    "    for rel in relations[:len(relations)-1]:\n",
    "        nbRel+=1\n",
    "        nbRelationPred += 1\n",
    "        \n",
    "        query = \"\"\n",
    "        context=''\n",
    "        nbContext = getContext(tokText,rel[5])\n",
    "        context = tokText[nbContext].replace('\"',\"'\" )\n",
    "        \n",
    "        \n",
    "        \n",
    "        if rel[1] in listeDoublon and rel[3] not in listeDoublon :\n",
    "            \n",
    "            query =  \"MATCH ( T1:\" + rel[1] + \"{nom:\\\"\" + rel[2] + \"\\\" , id :\\\"\" + '{}'.format(rel[5]) + \"\\\"} ) \"\n",
    "            query += \"MATCH ( T2:\" + rel[3] + \"{nom:\\\"\" + rel[4] + \"\\\"} ) \"\n",
    "\n",
    "            query += \"OPTIONAL MATCH (( T1 )-[r1:\" + rel[0] + \"]->( T2 )) \"\n",
    "            query +=\"FOREACH (usertype IN CASE WHEN exists (( T1 )-[:\" + rel[0] + \"]->( T2 )) = False  THEN [1] ELSE [] END | MERGE ( T1 )-[:\" + rel[0] + \" {context : [\\\"\"+context+\"\\\"],type : 'P',file:\\\"\"+file_path+\"\\\"} ]->( T2 ) ) \"\n",
    "            query +=\"FOREACH (usertype IN CASE WHEN exists (( T1 )-[:\" + rel[0] + \"]->( T2 )) = True  THEN [1] ELSE [] END | SET r1.context = r1.context + \\\"\"+ context +\"\\\") \"\n",
    "\n",
    "        elif rel[1] not in listeDoublon and rel[3]  in listeDoublon:\n",
    "            query =  \"MATCH ( T1:\" + rel[1] + \"{nom:\\\"\" + rel[2] + \"\\\"} ) \"\n",
    "            query += \"MATCH ( T2:\" + rel[3] + \"{nom:\\\"\" + rel[4] + \"\\\" , id :\\\"\" + '{}'.format(rel[5]) + \"\\\"} ) \"\n",
    "            \n",
    "            query += \"OPTIONAL MATCH (( T1 )-[r1:\" + rel[0] + \"]->( T2 )) \"\n",
    "            query +=\"FOREACH (usertype IN CASE WHEN exists (( T1 )-[:\" + rel[0] + \"]->( T2 )) = False  THEN [1] ELSE [] END | MERGE ( T1 )-[:\" + rel[0] + \" {context : [\\\"\"+context+\"\\\"],type : 'P',file:\\\"\"+file_path+\"\\\"} ]->( T2 ) ) \"\n",
    "            query +=\"FOREACH (usertype IN CASE WHEN exists (( T1 )-[:\" + rel[0] + \"]->( T2 )) = True  THEN [1] ELSE [] END | SET r1.context = r1.context + \\\"\"+ context +\"\\\") \"\n",
    "\n",
    "        elif rel[1] in listeDoublon and rel[3]  in listeDoublon :\n",
    "            \n",
    "            query =  \"MERGE ( T1:\" + rel[1] + \"{nom:\\\"\" + rel[2] + \"\\\" , id :\\\"\" + '{}'.format(rel[5]) + \"\\\"} ) -[:\" + rel[0] + \" {context : [\\\"\"+context+\"\\\"],type : 'P',file:\\\"\"+file_path+\"\\\"} ]->  ( T2:\" + rel[3] + \"{nom:\\\"\" + rel[4] + \"\\\" , id :\\\"\" + '{}'.format(rel[5]) + \"\\\"} ) \"\n",
    "\n",
    "        else :\n",
    "            query =  \"MATCH ( T1:\" + rel[1] + \"{nom:\\\"\" + rel[2] + \"\\\"} ) \"\n",
    "            query += \"MATCH ( T2:\" + rel[3] + \"{nom:\\\"\" + rel[4] + \"\\\"} ) \"\n",
    "\n",
    "\n",
    "            query += \"OPTIONAL MATCH (( T1 )-[r1:\" + rel[0] + \"]->( T2 )) \"\n",
    "            query +=\"FOREACH (usertype IN CASE WHEN exists (( T1 )-[:\" + rel[0] + \"]->( T2 )) = False  THEN [1] ELSE [] END | MERGE ( T1 )-[:\" + rel[0] + \" {context : [\\\"\"+context+\"\\\"],type : 'P',file:\\\"\"+file_path+\"\\\"} ]->( T2 ) ) \"\n",
    "            query +=\"FOREACH (usertype IN CASE WHEN exists (( T1 )-[:\" + rel[0] + \"]->( T2 )) = True  THEN [1] ELSE [] END | SET r1.context = r1.context + \\\"\"+ context +\"\\\") \"\n",
    "\n",
    "   \n",
    "        driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"i-0578b6cebb222aa18\"))\n",
    "        driver.session().run(query) \n",
    "print(\"nb relations : {}\".format(nbRel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entites annoté : 668 | entites predites 583\n",
      "Relations annoté : 233 | relations predites 67\n"
     ]
    }
   ],
   "source": [
    "print(\"Entites annoté : {} | entites predites {}\".format(nbEntiteAnn,nbEntitePred))\n",
    "print(\"Relations annoté : {} | relations predites {}\".format(nbRelationAnn,nbRelationPred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
